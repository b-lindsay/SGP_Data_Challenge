{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d0fba298dd4674a",
   "metadata": {},
   "source": [
    "# SailGP Data Analyst Challenge\n",
    "\n",
    "The aim is to test you python abilities. The challenge is to analyze the data provided and answer the questions below. You can use any library you want to help you with the analysis. The data is from the SailGP event in Auckland 2025. The data is in the 'DATA' folder.\n",
    "\n",
    "There are various sources available.\n",
    "\n",
    "The Boat Logs are in the 'Boat_Logs' folder. The data is in csv format and the columns are described in the 'Boat_Logs/Boat_Logs_Columns.csv' file.\n",
    "The 'Course_Marks_2025-01-19.csv' file contains the mark positions and wind reading on the course for the whole day.\n",
    "\n",
    "The Race_XML folder contains the xml files for each race that contains information on where the boundaries of the course are, the theoretical position of the marks and the target racecourse axis.\n",
    "\n",
    "The 2025-01-19_man_summary.csv file contains the metrics from the manoeuvre summary for the day.\n",
    "The 2025-01-19_straight_lines.csv file contains the metrics from the straight line summary for the day.\n",
    "\n",
    "Both are derived from the boat logs.\n",
    "\n",
    "The 2502 m8_APW_HSB2_HSRW.kph.csv file contains the polar data for the boats in that config.\n",
    "\n",
    "## Requierements\n",
    "- Chose at least 3 questions from the list below to answer.\n",
    "- Python 3.8 or higher\n",
    "- Notebook should be able to run without any errors from start to finish.\n",
    "- Specify the libraries (imports) used in the notebook.\n",
    "- Any comments to make the notebook self-explanatory and easy to follow would be appreciated.\n",
    "- If you can't get to the end of a question, we would appreciate the code you have written so far and explain what you were trying to do.\n",
    "\n",
    "## Further information:\n",
    "- We usually use bokeh for visualizations. So any showcase of bokeh would be appreciated.\n",
    "-\n",
    "\n",
    "## Submitting the results.\n",
    "It would be great if you could provide a jupyter notebook with the code and the results of the analysis. You can submit the results by sharing a link to a git repository.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c766dfd4d17a82",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Imports and re-used functions\n",
    "Free section to initialize the notebook with the necessary imports and functions that will be used in the notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c3955f6358cd7b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'SGP_Data_Challenge' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/DrSailGP/SGP_Data_Challenge.git\n",
    "!cd SGP_Data_Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a20b54fd-f565-4c16-922f-3b8fb3ff5f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: bokeh in /opt/anaconda3/lib/python3.12/site-packages (3.6.0)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.12/site-packages (3.9.2)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (1.13.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: Jinja2>=2.9 in /opt/anaconda3/lib/python3.12/site-packages (from bokeh) (3.1.4)\n",
      "Requirement already satisfied: contourpy>=1.2 in /opt/anaconda3/lib/python3.12/site-packages (from bokeh) (1.2.0)\n",
      "Requirement already satisfied: packaging>=16.8 in /opt/anaconda3/lib/python3.12/site-packages (from bokeh) (24.1)\n",
      "Requirement already satisfied: pillow>=7.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from bokeh) (10.4.0)\n",
      "Requirement already satisfied: PyYAML>=3.10 in /opt/anaconda3/lib/python3.12/site-packages (from bokeh) (6.0.1)\n",
      "Requirement already satisfied: tornado>=6.2 in /opt/anaconda3/lib/python3.12/site-packages (from bokeh) (6.4.1)\n",
      "Requirement already satisfied: xyzservices>=2021.09.1 in /opt/anaconda3/lib/python3.12/site-packages (from bokeh) (2022.9.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from Jinja2>=2.9->bokeh) (2.1.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas numpy bokeh matplotlib scipy math bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472e559e-57f3-4b24-9d17-52515789249f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2025-02-08 21:38:06.803 ServerApp]\u001b[m Extension package aext_assistant took 0.6992s to import\n",
      "\u001b[32m[I 2025-02-08 21:38:06.814 ServerApp]\u001b[m ****************** ENVIRONMENT [Panels] Environment.PRODUCTION ******************\n",
      "\u001b[32m[I 2025-02-08 21:38:06.815 ServerApp]\u001b[m ****************** ENVIRONMENT [Panels] Environment.PRODUCTION ******************\n",
      "\u001b[32m[I 2025-02-08 21:38:06.906 ServerApp]\u001b[m --> Alembic Config: {'db_conn_url': 'sqlite:////Users/blindsay/anaconda_projects/db/project_filebrowser.db', 'db_path': '/Users/blindsay/anaconda_projects/db/project_filebrowser.db'}\n",
      "\u001b[32m[I 2025-02-08 21:38:06.906 ServerApp]\u001b[m Default dir: /Users/blindsay. Running chdir...\n",
      "\u001b[32m[I 2025-02-08 21:38:06.906 ServerApp]\u001b[m Checking for database file @ /Users/blindsay/anaconda_projects/db/project_filebrowser.db\n",
      "\u001b[32m[I 2025-02-08 21:38:06.906 ServerApp]\u001b[m Database file already exists\n",
      "\u001b[32m[I 2025-02-08 21:38:06.915 ServerApp]\u001b[m Migrations executed\n",
      "\u001b[32m[I 2025-02-08 21:38:06.915 ServerApp]\u001b[m Checking project configuration: /Users/blindsay. Running chdir...\n",
      "\u001b[32m[I 2025-02-08 21:38:06.931 ServerApp]\u001b[m Extension package aext_toolbox took 0.1138s to import\n",
      "\u001b[33m[W 2025-02-08 21:38:06.968 ServerApp]\u001b[m A `_jupyter_server_extension_points` function was not found in jupyter_lsp. Instead, a `_jupyter_server_extension_paths` function was found and will be used for now. This function name will be deprecated in future releases of Jupyter Server.\n",
      "\u001b[33m[W 2025-02-08 21:38:07.001 ServerApp]\u001b[m A `_jupyter_server_extension_points` function was not found in notebook_shim. Instead, a `_jupyter_server_extension_paths` function was found and will be used for now. This function name will be deprecated in future releases of Jupyter Server.\n",
      "\u001b[32m[I 2025-02-08 21:38:07.521 ServerApp]\u001b[m Extension package panel.io.jupyter_server_extension took 0.5194s to import\n",
      "\u001b[32m[I 2025-02-08 21:38:07.521 ServerApp]\u001b[m aext_assistant | extension was successfully linked.\n",
      "\u001b[32m[I 2025-02-08 21:38:07.521 ServerApp]\u001b[m aext_core | extension was successfully linked.\n",
      "\u001b[32m[I 2025-02-08 21:38:07.521 ServerApp]\u001b[m aext_panels | extension was successfully linked.\n",
      "\u001b[32m[I 2025-02-08 21:38:07.521 ServerApp]\u001b[m aext_share_notebook | extension was successfully linked.\n",
      "\u001b[32m[I 2025-02-08 21:38:07.521 ServerApp]\u001b[m aext_toolbox | extension was successfully linked.\n",
      "\u001b[32m[I 2025-02-08 21:38:07.521 ServerApp]\u001b[m jupyter_lsp | extension was successfully linked.\n",
      "\u001b[32m[I 2025-02-08 21:38:07.523 ServerApp]\u001b[m jupyter_server_terminals | extension was successfully linked.\n",
      "\u001b[32m[I 2025-02-08 21:38:07.525 ServerApp]\u001b[m jupyterlab | extension was successfully linked.\n",
      "\u001b[32m[I 2025-02-08 21:38:07.526 ServerApp]\u001b[m notebook | extension was successfully linked.\n",
      "\u001b[32m[I 2025-02-08 21:38:07.695 ServerApp]\u001b[m notebook_shim | extension was successfully linked.\n",
      "\u001b[32m[I 2025-02-08 21:38:07.695 ServerApp]\u001b[m panel.io.jupyter_server_extension | extension was successfully linked.\n",
      "\u001b[32m[I 2025-02-08 21:38:08.270 ServerApp]\u001b[m nb_conda_kernels | enabled, 1 kernels found.\n",
      "\u001b[32m[I 2025-02-08 21:38:08.280 ServerApp]\u001b[m notebook_shim | extension was successfully loaded.\n",
      "\u001b[32m[I 2025-02-08 21:38:08.280 ServerApp]\u001b[m Registered aext_assistant server extension\n",
      "\u001b[32m[I 2025-02-08 21:38:08.280 ServerApp]\u001b[m aext_assistant | extension was successfully loaded.\n",
      "\u001b[32m[I 2025-02-08 21:38:08.281 ServerApp]\u001b[m Registered aext_core server extension\n",
      "\u001b[32m[I 2025-02-08 21:38:08.281 ServerApp]\u001b[m aext_core | extension was successfully loaded.\n",
      "\u001b[32m[I 2025-02-08 21:38:08.281 ServerApp]\u001b[m Registered aext_panels server extension\n",
      "\u001b[32m[I 2025-02-08 21:38:08.281 ServerApp]\u001b[m aext_panels | extension was successfully loaded.\n",
      "\u001b[32m[I 2025-02-08 21:38:08.281 ServerApp]\u001b[m Registered aext_share_notebook_server server extension\n",
      "\u001b[32m[I 2025-02-08 21:38:08.281 ServerApp]\u001b[m aext_share_notebook | extension was successfully loaded.\n",
      "\u001b[32m[I 2025-02-08 21:38:08.282 ServerApp]\u001b[m Registered aext_project_filebrowser_server extension\n",
      "\u001b[32m[I 2025-02-08 21:38:08.282 ServerApp]\u001b[m Registered aext_toolbox extension\n",
      "\u001b[32m[I 2025-02-08 21:38:08.282 ServerApp]\u001b[m aext_toolbox | extension was successfully loaded.\n",
      "\u001b[32m[I 2025-02-08 21:38:08.283 ServerApp]\u001b[m jupyter_lsp | extension was successfully loaded.\n",
      "\u001b[32m[I 2025-02-08 21:38:08.284 ServerApp]\u001b[m jupyter_server_terminals | extension was successfully loaded.\n",
      "\u001b[32m[I 2025-02-08 21:38:08.286 LabApp]\u001b[m JupyterLab extension loaded from /opt/anaconda3/lib/python3.12/site-packages/jupyterlab\n",
      "\u001b[32m[I 2025-02-08 21:38:08.286 LabApp]\u001b[m JupyterLab application directory is /opt/anaconda3/share/jupyter/lab\n",
      "\u001b[32m[I 2025-02-08 21:38:08.287 LabApp]\u001b[m Extension Manager is 'pypi'.\n",
      "\u001b[32m[I 2025-02-08 21:38:08.302 ServerApp]\u001b[m jupyterlab | extension was successfully loaded.\n",
      "\u001b[32m[I 2025-02-08 21:38:08.304 ServerApp]\u001b[m notebook | extension was successfully loaded.\n",
      "\u001b[32m[I 2025-02-08 21:38:08.304 ServerApp]\u001b[m panel.io.jupyter_server_extension | extension was successfully loaded.\n",
      "\u001b[32m[I 2025-02-08 21:38:08.305 ServerApp]\u001b[m The port 8888 is already in use, trying another port.\n",
      "\u001b[32m[I 2025-02-08 21:38:08.305 ServerApp]\u001b[m The port 8889 is already in use, trying another port.\n",
      "\u001b[32m[I 2025-02-08 21:38:08.306 ServerApp]\u001b[m The port 8890 is already in use, trying another port.\n",
      "\u001b[32m[I 2025-02-08 21:38:08.306 ServerApp]\u001b[m The port 8891 is already in use, trying another port.\n",
      "\u001b[32m[I 2025-02-08 21:38:08.306 ServerApp]\u001b[m The port 8892 is already in use, trying another port.\n",
      "\u001b[32m[I 2025-02-08 21:38:08.307 ServerApp]\u001b[m Serving notebooks from local directory: /Users/blindsay\n",
      "\u001b[32m[I 2025-02-08 21:38:08.307 ServerApp]\u001b[m Jupyter Server 2.14.1 is running at:\n",
      "\u001b[32m[I 2025-02-08 21:38:08.307 ServerApp]\u001b[m http://localhost:8988/tree?token=d6798f840a9bf125950d67257ba22e58d73ef147ec7caa94\n",
      "\u001b[32m[I 2025-02-08 21:38:08.307 ServerApp]\u001b[m     http://127.0.0.1:8988/tree?token=d6798f840a9bf125950d67257ba22e58d73ef147ec7caa94\n",
      "\u001b[32m[I 2025-02-08 21:38:08.307 ServerApp]\u001b[m Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).\n",
      "\u001b[35m[C 2025-02-08 21:38:08.309 ServerApp]\u001b[m \n",
      "    \n",
      "    To access the server, open this file in a browser:\n",
      "        file:///Users/blindsay/Library/Jupyter/runtime/jpserver-43291-open.html\n",
      "    Or copy and paste one of these URLs:\n",
      "        http://localhost:8988/tree?token=d6798f840a9bf125950d67257ba22e58d73ef147ec7caa94\n",
      "        http://127.0.0.1:8988/tree?token=d6798f840a9bf125950d67257ba22e58d73ef147ec7caa94\n",
      "\u001b[32m[I 2025-02-08 21:38:08.481 ServerApp]\u001b[m Skipped non-installed server(s): bash-language-server, dockerfile-language-server-nodejs, javascript-typescript-langserver, jedi-language-server, julia-language-server, pyright, python-language-server, r-languageserver, sql-language-server, texlab, typescript-language-server, unified-language-server, vscode-css-languageserver-bin, vscode-html-languageserver-bin, vscode-json-languageserver-bin, yaml-language-server\n",
      "\u001b[32m[I 2025-02-08 21:38:09.523 JupyterNotebookApp]\u001b[m 302 GET /tree/main.ipynb?token=[secret] (7194a20b89f04d989cecd40d9ac064b5@::1) 4.71ms\n",
      "\u001b[31m[E 2025-02-08 21:38:10.339 ServerApp]\u001b[m Uncaught exception GET /aext_core_server/feature_flag/init?1739075890293 (::1)\n",
      "    HTTPServerRequest(protocol='http', host='localhost:8988', method='GET', uri='/aext_core_server/feature_flag/init?1739075890293', version='HTTP/1.1', remote_ip='::1')\n",
      "    Traceback (most recent call last):\n",
      "      File \"/opt/anaconda3/lib/python3.12/site-packages/tornado/web.py\", line 1790, in _execute\n",
      "        result = await result\n",
      "                 ^^^^^^^^^^^^\n",
      "      File \"/opt/anaconda3/lib/python3.12/site-packages/aext_core_server/handlers.py\", line 29, in get\n",
      "        [account, organizations, account_notebooks] = await asyncio.gather(\n",
      "                                                      ^^^^^^^^^^^^^^^^^^^^^\n",
      "      File \"/opt/anaconda3/lib/python3.12/site-packages/aext_shared/handler.py\", line 132, in anaconda_cloud_proxy\n",
      "        user_access_credentials = await self.get_user_access_credentials(auth_optional=auth_optional)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "      File \"/opt/anaconda3/lib/python3.12/site-packages/aext_shared/handler.py\", line 109, in get_user_access_credentials\n",
      "        raise e\n",
      "      File \"/opt/anaconda3/lib/python3.12/site-packages/aext_shared/handler.py\", line 106, in get_user_access_credentials\n",
      "        new_access_token, expires_in = await get_access_token(self.request)\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "      File \"/opt/anaconda3/lib/python3.12/site-packages/aext_shared/handler.py\", line 189, in get_access_token\n",
      "        raise UnauthorizedError({\"reason\": \"missing refresh_token\"})\n",
      "    aext_shared.errors.UnauthorizedError: BackendError 403: missing refresh_token\n",
      "\u001b[33m[W 2025-02-08 21:38:10.342 ServerApp]\u001b[m 403 GET /aext_core_server/feature_flag/init?1739075890293 (7194a20b89f04d989cecd40d9ac064b5@::1) 37.58ms referer=http://localhost:8988/notebooks/main.ipynb\n",
      "\u001b[33m[W 2025-02-08 21:38:10.749 ServerApp]\u001b[m 404 GET /aext_profile_manager_server/account_details?1739075890677 (7194a20b89f04d989cecd40d9ac064b5@::1) 9.15ms referer=http://localhost:8988/notebooks/main.ipynb\n",
      "\u001b[33m[W 2025-02-08 21:38:10.884 ServerApp]\u001b[m wrote error: 'Forbidden'\n",
      "    Traceback (most recent call last):\n",
      "      File \"/opt/anaconda3/lib/python3.12/site-packages/tornado/web.py\", line 1790, in _execute\n",
      "        result = await result\n",
      "                 ^^^^^^^^^^^^\n",
      "      File \"/opt/anaconda3/lib/python3.12/site-packages/aext_assistant_server/handlers.py\", line 117, in get\n",
      "        raise HTTPError(403, reason=\"missing nucleus_token\")\n",
      "    tornado.web.HTTPError: HTTP 403: missing nucleus_token\n",
      "\u001b[33m[W 2025-02-08 21:38:10.885 ServerApp]\u001b[m 403 GET /aext_assistant_server/nucleus_token?1739075890882 (7194a20b89f04d989cecd40d9ac064b5@::1) 2.34ms referer=http://localhost:8988/notebooks/main.ipynb\n",
      "\u001b[32m[I 2025-02-08 21:38:11.390 ServerApp]\u001b[m Kernel started: b0fda3e8-fdc0-4458-9b14-5a6ecb78b84d\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "\u001b[32m[I 2025-02-08 21:38:11.848 ServerApp]\u001b[m Connecting to kernel b0fda3e8-fdc0-4458-9b14-5a6ecb78b84d.\n",
      "\u001b[32m[I 2025-02-08 21:38:11.849 ServerApp]\u001b[m Connecting to kernel b0fda3e8-fdc0-4458-9b14-5a6ecb78b84d.\n",
      "\u001b[32m[I 2025-02-08 21:38:11.861 ServerApp]\u001b[m Connecting to kernel b0fda3e8-fdc0-4458-9b14-5a6ecb78b84d.\n",
      "\u001b[32m[I 2025-02-08 21:38:18.099 ServerApp]\u001b[m Starting buffering for b0fda3e8-fdc0-4458-9b14-5a6ecb78b84d:a2dbf2b7-bbc3-4df0-b785-21396242ca5c\n"
     ]
    }
   ],
   "source": [
    "#!jupyter notebook main_final.ipynb #change back to!jupyter notebook main.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d166957248f0f7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Question 1: Write a Python function that can take a compass direction (ie. TWD or Heading) and calculate an accurate mean value across a downsampled frequency. Eg. If TWD is at 1Hz, give me a 10s average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75556c527d1bf0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DONE\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "def downsampled_mean (compass_dir, og_frequency, dwnsmpl_freq):\n",
    "    \n",
    "    for i in range (0, len(compass_dir), (og_frequency*dwnsmpl_freq)):\n",
    "        ds = compass_dir[i:i + (og_frequency*dwnsmpl_freq)]\n",
    "        ds_mean = np.mean(ds)\n",
    "\n",
    "    return print(ds_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72fe07f7-5e04-4f0e-8a3e-f85f725e8a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109.18\n",
      "118.21375\n"
     ]
    }
   ],
   "source": [
    "#CODE TO CHECK THAT IT RUNS \n",
    "sample_df = pd.read_csv('SGP_Data_Challenge/Data/Boat_logs/data_BRA.csv')\n",
    "compass_dir = sample_df['HEADING_deg']\n",
    "#TWD is at 1Hz, give me a 10s average.\n",
    "downsampled_mean(compass_dir, 1, 10)\n",
    "\n",
    "#TWD is at 1Hz, give me a 100s average.\n",
    "downsampled_mean(compass_dir, 1, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa948eea67b6d187",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Question 2: Given a course XML and a timeseries of boat Lat/Lon values, calculate a VMC column for the same timeseries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "215a1b096ddf991a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DONE \n",
    "from bs4 import BeautifulSoup\n",
    "import math \n",
    "\n",
    "#get marks from XLM and return coordinates for legs\n",
    "def find_mark(XML_file):\n",
    "   \n",
    "    with open(XML_file, 'r', encoding='utf-8') as file:\n",
    "        soup = BeautifulSoup(file, 'xml')\n",
    "\n",
    "    mark_coords = {} #find mark lat and long from XLM \n",
    "    for all_marks in soup.find_all(\"CompoundMark\"):\n",
    "        for mark in all_marks.findall(\"Mark\"):\n",
    "            ID_mark = mark.get('CompoundMarkID')\n",
    "            if ID_mark:\n",
    "                mark_coords[ID_mark] = (\n",
    "                    float(mark.gat('TargetLat', 0)),\n",
    "                    float(mark.get('TargetLng', 0))\n",
    "                )\n",
    "            \n",
    "    course = []\n",
    "    for corner in soup.find_all(\"Corner\"):\n",
    "        ID_mark = corner.get('CompoundMarkID')\n",
    "        if ID_mark in mark_coords:\n",
    "            course.append(mark_coords[ID_mark])\n",
    "\n",
    "    legs = []\n",
    "    for i in range(len(course) - 1):\n",
    "        last_mark = course[i] #last mark sailed\n",
    "        next_mark = course[i + 1] #next mark sailing to \n",
    "        legs.append((last_mark, next_mark))\n",
    "    return legs\n",
    "\n",
    "#calculate distance between coodinates using Spherical Law of Cosines\n",
    "def distance(coord1, coord2):\n",
    "    lat1, lon1 = map(math.radians, coord1)\n",
    "    lat2, lon2 = map(math.radians, coord2)\n",
    "    \n",
    "   ##add explination for how SLC is being used *******\n",
    "    diff_lon = lon2 - lon1\n",
    "    dist = math.acos(math.sin(lat1) * math.sin(lat2) + math.cos(lat1) * math.cos(lat2) * math.cos(diff_lon)) * 6371 #earth radius in km\n",
    "\n",
    "    return round(dist, 3)\n",
    "\n",
    "#calculate heading in deg\n",
    "def heading(coord1, coord2):\n",
    "    lat1, lon1 = map(math.radians, coord1)\n",
    "    lat2, lon2 = map(math.radians, coord2)\n",
    "\n",
    "    diff_lon = lon2 - lon1\n",
    "    x = math.sin(diff_lon) * math.cos(lat2)\n",
    "    y = math.cos(lat1) * math.sin(lat2) - math.sin(lat1) * math.cos(lat2) * math.cos(diff_lon)\n",
    "\n",
    "    heading = math.atan2(x,y)\n",
    "    return round((math.degrees(heading) + 360) % 360,)\n",
    "\n",
    "#caluclate VMC\n",
    "def VMC(time_lat_lon, lat_lon_target):\n",
    "    vmc = []\n",
    "\n",
    "    for i in range(len(time_lat_lon) - 1):\n",
    "        time1, lat1, lon1 = time_lat_lon[i]\n",
    "        time2, lat2, lon2 = time_lat_lon[i +1]\n",
    "\n",
    "    #time diff in sec\n",
    "        diff_time = (time2 - time1).total_seconds()\n",
    "\n",
    "    #boatstpeed (sog) in kts\n",
    "        dist = distance((lat1, lon1), (lat2, lon2))\n",
    "        sog = dist / (diff_time / 3600) #convert to kts\n",
    "    \n",
    "    #heading\n",
    "        boat_heading = heading((lat1, lon1), (lat2, lon2))\n",
    "        target_course = heading((lat2, lon2), lat_lon_target)\n",
    "\n",
    "    #vmc = sog * cos(abs(heading - target_course)\n",
    "        vmc_calc = round(sog * abs(math.cos(math.radians(abs(boat_heading - target_course)))), 2)\n",
    "        vmc.append(vmc_calc)\n",
    "        \n",
    "    return vmc\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e2fbf7-8936-4937-8542-a6509ed55371",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE TO CHECK THAT IT RUNS \n",
    "\n",
    "file_path = \"SGP_Data_Challenge/Data/Race_XMLs/25011905_03-13-55.xml\"\n",
    "\n",
    "from datetime import datetime\n",
    "# time_lat_lon = [\n",
    "#         (datetime(2025, 1, 19, 16, 6, 0), -36.8334, 174.759),\n",
    "#         (datetime(2025, 1, 19, 16, 7, 0), -36.833, 174.759),\n",
    "#         (datetime(2025, 1, 19, 16, 8, 0), -36.834, 174.769),\n",
    "#         (datetime(2025, 1, 19, 16, 9, 0), -36.833, 174.768),\n",
    "#         (datetime(2025, 1, 19, 16, 10, 0), -36.832, 174.767),\n",
    "        \n",
    "# ]\n",
    "\n",
    "time_lat_lon = \n",
    "lat_lon_target= (-36.8297130, 174.7652700)\n",
    "\n",
    "VMC(time_lat_lon,lat_lon_target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59eded55c0230916",
   "metadata": {},
   "source": [
    "## Question 3: Verify and comment on the boats calibration. If possible propose a post-calibrated set of wind numbers and a potential calibration table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0fa8ab74285ef0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9be5cb7d6e14e29",
   "metadata": {},
   "source": [
    "## Question 4: Given a timeseries of Lat/Lon positions and a course XML, in a Python notebook, calculate a Distance to Leader metric for each boat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c225a8b3cf1e382e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c23f6f44eac779",
   "metadata": {},
   "source": [
    "## Question 5: Given a course XML, along with a wind speed and direction and a polar, calculate the minimum number of tacks or gybes for each leg of the course and each gate mark on the leg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55a57d792cc4849",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49813bad6749aff0",
   "metadata": {},
   "source": [
    "## Question 6: Calculate a “tacked” set of variables depending on the tack of the boat, so that sailors don’t need to think about what tack they’re on when looking at measurements. And show the results in a visualisation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939047c7233179e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48f959e7cb85e711",
   "metadata": {},
   "source": [
    "## Question 7: Given a set of tacks (in CSV), and train a model to explain the key features of these tacks when optimizing for vmg. Show appropriate visualisations to explain your conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "9b8435876f454825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 2.3576061986098695\n",
      "Mean Squared Error: 8.029454699028225\n",
      "Root Mean Squared Error: 2.8336292451603873\n",
      "R-squared: 0.9384132857024592\n",
      "num outliers: 0\n",
      "outlier indicies: []\n"
     ]
    }
   ],
   "source": [
    "#Running a Random Forest Regressor \n",
    "#we have a mix of continuous and a few categorical variables\n",
    "#random forestshould help with overfitting \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from bokeh.palettes import Spectral11\n",
    "from scipy.stats import zscore \n",
    "\n",
    "#load in maneuver dataset \n",
    "man_summary_19 = pd.read_csv('SGP_Data_Challenge/Data/2025-01-19_man_summary.csv')\n",
    "tacks = man_summary_19[man_summary_19['type'] != 'gybe']\n",
    "\n",
    "#seperate response y and explanatory x variables\n",
    "y = tacks['theoretical_vmg']\n",
    "\n",
    "X = tacks.drop(columns = ['theoretical_vmg', 'BOAT', 'HULL', 'DATETIME', 'TIME_LOCAL_unk',\n",
    "                          'dashboard', 'htw_bsp', 'entry_tack', 'type', 'drop_time_P',\n",
    "                          'drop_time_S', 'unstow_time_P', 'unstow_time_S', 'stow_time_P',\n",
    "                          'stow_time_S', 'boards_up_time_S', 'boards_up_time_P', \n",
    "                          'max_lat_gforce', 'max_fwd_gforce', 'max_gforce', 'theoretical_distance',\n",
    "                          'MD4_SEL_DB_unk', 'MD4_SEL_RUD_unk', 'WING_CONFIG_unk', 'leg', 'race'], axis=1)\n",
    "\n",
    "#spit data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.02, random_state=42)\n",
    "\n",
    "#initialize random forest regressor\n",
    "model = RandomForestRegressor(n_estimators=200, random_state=42)\n",
    "\n",
    "#train model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "MAE = mean_absolute_error(y_test, y_pred)\n",
    "MSE = mean_squared_error(y_test, y_pred)\n",
    "RMSE = np.sqrt(MSE)\n",
    "R2 = r2_score(y_test, y_pred)\n",
    "print(f'Mean Absolute Error: {MAE}') #on avg predictions are off by 2.24 units from true value\n",
    "print(f'Mean Squared Error: {MSE}') #MSE is only 10.5% of total range, so relativley small\n",
    "print(f'Root Mean Squared Error: {RMSE}') #model error is about 2.9 units, decent accureacy \n",
    "print(f'R-squared: {R2}') #model explains 94% of variance in theoretical vmg, strong model \n",
    "#model has low error values and a high r squared, so it is good\n",
    "\n",
    "#checking for outliers \n",
    "residuals = y_test - y_pred\n",
    "residuals_z = np.abs(zscore(residuals))\n",
    "outliers = residuals_z > 3 \n",
    "\n",
    "print(\"num outliers:\", np.sum(outliers))\n",
    "print('outlier indicies:', np.where(outliers)[0])\n",
    "\n",
    "# #regularizing model \n",
    "# param_grid = {\n",
    "#     'n_estimators': [50,100,200],\n",
    "#     'max_depth': [5, 10, 20, None],\n",
    "#     \"min_samples_split\": [2, 5, 10],\n",
    "#     \"min_samples_leaf\": [1,2,4],\n",
    "#     \"max_features\": [\"sqrt\", \"log2\", None],\n",
    "#     \"bootstrap\": [True, False]\n",
    "# }\n",
    "\n",
    "# rf = RandomForestRegressor(random_state = 42)\n",
    "\n",
    "#grid search with 5-fold cross validation\n",
    "# grid_search = GridSearchCV(rf, param_grid, cv=5, scoring=\"neg_mean_squared_error\", n_jobs=-1)\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# best_params = grid_search.best_params_\n",
    "# print(best_params)\n",
    "\n",
    "# best_rf = RandomForestRegressor(**best_params, random_state = 42)\n",
    "# best_rf.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = best_rf.predict(X_test)\n",
    "# #model will benefit form shallower tree, bootstrapping, 200 estimators, all features \n",
    "# best_rf = RandomForestRegressor(\n",
    "#     bootstrap= True,\n",
    "#     max_depth =10, \n",
    "#     max_features=None, \n",
    "#     min_samples_leaf=1,\n",
    "#     min_samples_split=2, \n",
    "#     n_estimators = 200,\n",
    "#     random_state =42\n",
    "# )\n",
    "\n",
    "# best_rf.fit(X_train, y_train)\n",
    "# y_pred = best_rf.predict(X_test)\n",
    "\n",
    "# MAE2 = mean_absolute_error(y_test, y_pred)\n",
    "# MSE2 = mean_squared_error(y_test, y_pred)\n",
    "# RMSE2 = np.sqrt(MSE)\n",
    "# R2_2 = r2_score(y_test, y_pred)\n",
    "# print(f'Mean Absolute Error2: {MAE2}') #on avg predictions are off by 2.24 units from true value\n",
    "# print(f'Mean Squared Error2: {MSE2}') #large prediction errors are contributing to overall error \n",
    "# print(f'Root Mean Squared Error2: {RMSE2}') #model error is about 2.9 units, decent accureacy \n",
    "# print(f'R-squared2: {R2_2}') #model explains 94% of variance in theoretical vmg, strong model \n",
    "\n",
    "#####show which variables contribute to vmg the most and which don't \n",
    "#show which of the explanatory variables are important to optimizing vmg\n",
    "# important_vars = model.feature_importances_\n",
    "\n",
    "# #create df with the feature names and their importances\n",
    "# important_vars = important_vars.sort_values(by='Importance', ascending = False)\n",
    "# threshold = .005\n",
    "# significant_vars = important_vars[important_vars['Importance'] >= threshold]['Feature']\n",
    "\n",
    "# #new df with only the important variables \n",
    "# X_important = X[significant_vars]\n",
    "\n",
    "# #train new model just on these important Xs\n",
    "# model2 = RandomForestRegressor(n_estimators=1000)\n",
    "# model2.fit(X_important, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997ddc7b58fdbd02",
   "metadata": {},
   "source": [
    "## Question 8: Give insights on the racing on what made a team win or underperform in the race."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc977ed2340f1b78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
